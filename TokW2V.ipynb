{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import certifi\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING\n",
    "Load csv file with answer and question. Create a new column with answer+question and drop column id and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/faqs_uft8_QA.csv\", sep = \";\", encoding = 'utf8', quotechar = '\"')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substring(line):\n",
    "    car=line[-1]\n",
    "    if car!='.':\n",
    "        line=line+'.'\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].map(lambda x:x.replace('?','').replace('\"','').replace('. ',''))\n",
    "df['answer'] = df['answer'].map(lambda x:x.replace('. ',' ').replace('\"','').replace('?',''))\n",
    "\n",
    "df['QA'] = df['question'] + ' ' + df['answer']\n",
    "df['Y'] = 1\n",
    "\n",
    "df['QA'] = df['QA'].map(lambda x:x.replace('?','').replace('\"','').replace('. ','').replace('. ',''))\n",
    "df['QA'] = df['QA'].map(lambda x:substring(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP TWO COLUMNS ID AND TAG\n",
    "df = df.drop([\"id\",\"tag\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset/QA.txt\", header = False, encoding = 'utf-8', index = None, mode =\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION TEST PRE - PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Dataset/test-question.csv\", sep = \";\", encoding = 'utf8')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop([\"id\"], axis = 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileCreator(filename, data):\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAPI(filename, token, email):\n",
    "    f = open(filename)\n",
    "    data = {'token': token, 'service':'tok', 'email':email, 'authentication':'google', 'format':'plain'}\n",
    "    r = requests.post(url='http://tanl.di.unipi.it/it/api', data=data, files = {'file':f})\n",
    "    f.close()\n",
    "    out = open(filename, \"w\")\n",
    "    #print (r.text.encode('utf-8'))\n",
    "    out.write(r.text)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processingResponse(filename, gen):\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        ar = []\n",
    "        while line:\n",
    "            print(line)\n",
    "            item = str(line)\n",
    "            item = re.sub('\\n$', '', item)\n",
    "            item = re.sub('\\.$', '', item)\n",
    "            if (item != ''):\n",
    "                ar.append(item)\n",
    "            line = f.readline()\n",
    "        gen.append(ar)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(gen):\n",
    "    for elem in gen:\n",
    "        for e in elem:\n",
    "            if(e == \"\"):\n",
    "                elem.remove(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://tanl.di.unipi.it/it/overview.html\n",
    "token = ''\n",
    "email = ''\n",
    "\n",
    "X = [] #Question\n",
    "Y = [] #Answer\n",
    "Z = [] #Question+Answer\n",
    "T = [] #Test\n",
    "\n",
    "full=[] #Question+Answer+QuestionTest\n",
    "\n",
    "for (idx,row) in df2.iterrows():\n",
    "#for (idx,row) in df.iterrows():\n",
    "    #For each row Q+A\n",
    "    #data1 = row.loc['answer']\n",
    "    #data2 = row.loc['QA']\n",
    "    #data3 = row.loc['question']\n",
    "    dataTest = row.loc[\"question-test\"]\n",
    "    \n",
    "    #create file for TANL\n",
    "    fileCreator(\"toTokenizerQTest.txt\", dataTest)\n",
    "    #fileCreator(\"toTokenizerQA.txt\", data2)\n",
    "    #fileCreator(\"toTokenizerOnlyA.txt\", data1)\n",
    "    #fileCreator(\"toTokenizerOnlyQ.txt\", data3)\n",
    "    \n",
    "    #call API - return tokenized\n",
    "    #callAPI(\"toTokenizerQA.txt\",token, email)\n",
    "    #callAPI(\"toTokenizerOnlyA.txt\",token, email)\n",
    "    #callAPI(\"toTokenizerOnlyQ.txt\",token, email)\n",
    "    callAPI(\"toTokenizerQTest.txt\",token, email)\n",
    "    \n",
    "    #response manipulate\n",
    "    processingResponse(\"toTokenizerQTest.txt\", T)\n",
    "    #processingResponse(\"toTokenizerQA.txt\", Z)\n",
    "    #processingResponse(\"toTokenizerOnlyA.txt\", Y)\n",
    "    #processingResponse(\"toTokenizerOnlyQ.txt\", X)\n",
    "    #cleaning\n",
    "    full.extend(Z)\n",
    "    full.extend(T)\n",
    "    #cleaning(X)\n",
    "    #cleaning(Y)\n",
    "    #cleaning(Z)\n",
    "    cleaning(T)\n",
    "    #Sleep to avoid block request\n",
    "    print (\"SLEEP\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTIONS\n",
    "with open(\"tokenizerQuestion.txt\", \"w\") as f:\n",
    "    for elem in X:\n",
    "        f.write(\"[\\n\")\n",
    "        for item in elem:\n",
    "            item = str(item)\n",
    "            f.write(item + \"\\n\")\n",
    "        print (elem)\n",
    "        f.write(\"]\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANSWERS\n",
    "with open(\"tokenizerAnswer.txt\", \"w\") as f:\n",
    "    for elem in Y:\n",
    "        f.write(\"[\\n\")\n",
    "        for item in elem:\n",
    "            item = str(item)\n",
    "            f.write(item + \"\\n\")\n",
    "        print (elem)\n",
    "        f.write(\"]\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTIONS+ANSWERS\n",
    "with open(\"tokenizerQuestionAnswer.txt\", \"w\") as f:\n",
    "    for elem in Z:\n",
    "        f.write(\"[\\n\")\n",
    "        for item in elem:\n",
    "            item = str(item)\n",
    "            f.write(item + \"\\n\")\n",
    "        print (elem)\n",
    "        f.write(\"]\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTIONS TEST\n",
    "with open(\"tokenizerQTest.txt\", \"w\") as f:\n",
    "    for elem in T:\n",
    "        f.write(\"[\\n\")\n",
    "        for item in elem:\n",
    "            item = str(item)\n",
    "            f.write(item + \"\\n\")\n",
    "        print (elem)\n",
    "        f.write(\"]\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word to Vect\n",
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "# train word2vec \n",
    "iterN = 10 #how many times the training code will run through the data set to train \n",
    "#the neural network (kind of like the number of training epochs).\n",
    "mc = 1 #specifies the minimum amount of times that the word has to appear in the corpus \n",
    "#before it is included in the vocabulary – this allows us to easily eliminate rare words \n",
    "#and reduce our vocabulary size\n",
    "s = 200 #In other words, each word in our vocabulary, after training, will be represented \n",
    "#by a 200 length word vector.\n",
    "job = 4 #parallel workers we would like to work on the data – this will speed up the training process\n",
    "window = 5 #contorno di 5 parole (default)\n",
    "\n",
    "#full\n",
    "modelFull = gensim.models.Word2Vec(full, iter = iterN, min_count=mc, size = s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save w2v model\n",
    "modelFull.save('model/mymodelFull')\n",
    "#load w2v model\n",
    "#new_model = gensim.models.Word2Vec.load('/tmp/mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFull.most_similar(['n335', 'posso', 'bolletta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFull.wv.syn0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some similarity fun\n",
    "print(modelFull.wv.similarity('come', 'bolletta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most common words\n",
    "print(modelFull.wv.index2word[0], modelFull.wv.index2word[1], modelFull.wv.index2word[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the least common words\n",
    "vocab_size = len(modelFull.wv.vocab)\n",
    "print(modelFull.wv.index2word[vocab_size - 1],modelFull.wv.index2word[vocab_size - 2], modelFull.wv.index2word[vocab_size - 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
